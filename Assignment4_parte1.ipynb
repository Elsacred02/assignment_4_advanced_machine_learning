{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elsacred02/assignment_4_advanced_machine_learning/blob/main/Assignment4_parte1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUCLfMnLh9Bt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'divina_commedia.txt'\n",
        "with open(path, encoding='utf-8') as f:\n",
        "  text = f.read().lower()\n",
        "print('Text length:', len(text))\n",
        "print()\n",
        "print(text[0:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "0J11rU3OkDe8",
        "outputId": "79ca5674-3889-44fd-b71d-c5f18c38bec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'divina_commedia.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1336174329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'divina_commedia.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Text length:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'divina_commedia.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "\n",
        "print('total chars:', len(chars))\n",
        "\n",
        "#from chars to numbers\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "# from numbert to chars\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(char_indices)\n",
        "print(indices_char)\n",
        "\n"
      ],
      "metadata": {
        "id": "2cP3STbbmU63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 30\n",
        "step = 2\n",
        "\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, 200000, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "\n",
        "print('number of sentences:', len(sentences))\n",
        "\n",
        "print(sentences[11])\n",
        "print(next_chars[11])"
      ],
      "metadata": {
        "id": "y0SeabpOnXBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars))) # 100,000 x 30 x 40\n",
        "y = np.zeros((len(sentences), len(chars))) # 100,000 x 40\n",
        "\n",
        "for i, (sentence, next_char) in enumerate(zip(sentences, next_chars)):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next_char]] = 1\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "yBASvhOJpbXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(30, 40, 1)),\n",
        "    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(chars), activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qefkktDGrM1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "import sys\n",
        "\n",
        "def testAfterEpoch(epoch, _):\n",
        "  if epoch < 10:\n",
        "    return\n",
        "  print()\n",
        "  print()\n",
        "  print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "  start_index = random.randint(0, len(text)-maxlen-1)\n",
        "\n",
        "  generated = ''\n",
        "  sentence = text[start_index: start_index + maxlen]\n",
        "  generated += sentence\n",
        "  print('**** starting sentence*****')\n",
        "  print(sentence)\n",
        "  print('***************************')\n",
        "  sys.stdout.write(generated)\n",
        "\n",
        "  for i in range(200):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      x_pred[0, t, char_indices[char]] = 1\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = np.argmax(preds)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    sentence = sentence[1:] + next_char\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "  print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=testAfterEpoch)\n",
        "\n"
      ],
      "metadata": {
        "id": "1vjCnaO9viMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,\n",
        "          batch_size=2048,\n",
        "          epochs=30,\n",
        "          callbacks = [print_callback])"
      ],
      "metadata": {
        "id": "tm7oXDRitQZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}